{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817f9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyclone\n",
    "# cfgs_all_jl\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cD211.054.96'\n",
    "\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "path=f'/nvme/h/cy22yl1/projectData/02_discNJN_1D/{ens}/data_pre_jl/'\n",
    "cfgs=[cfg2new(cfg) for cfg in os.listdir(path)]; cfgs.sort()\n",
    "\n",
    "with open('data_aux/cfgs_all_jl','w') as f:\n",
    "    f.write('\\n'.join(cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd94406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40         \r"
     ]
    }
   ],
   "source": [
    "# cyclone\n",
    "# cfgs_all_jg\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cD211.054.96'\n",
    "basePath='/onyx/qdata/gspanoudes/Local_operators/Matrix_elements/cD96/data/gluon_loops_stout/'\n",
    "stouts=range(40+1)\n",
    "replicas=['cD96a','cD96b','cD96c','cD96d']; labels=['a','b','c','d']\n",
    "\n",
    "replica2label={replica:label for replica,label in zip(replicas,labels)}\n",
    "label2replica={label:replica for replica,label in zip(replicas,labels)}\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "cfgs=[replica2label[replica]+cfg for replica in replicas for cfg in os.listdir(f'{basePath}stout{0}/{replica}')]\n",
    "cfgs.sort()\n",
    "\n",
    "cfg=cfgs[0]\n",
    "path=f'{basePath}stout{0}/{label2replica[cfg[0]]}/{cfg[1:]}/'\n",
    "sizes=[os.path.getsize(f'{path}{file}') for file in os.listdir(path)]\n",
    "\n",
    "cfgsDic={}\n",
    "for stout in stouts:\n",
    "    print(stout,end='         \\r')\n",
    "    t=[replica2label[replica]+cfg for replica in replicas for cfg in os.listdir(f'{basePath}stout{stout}/{replica}')]\n",
    "    t.sort()\n",
    "    assert(np.all(cfgs==t))\n",
    "    for cfg in cfgs:\n",
    "        path=f'{basePath}stout{stout}/{label2replica[cfg[0]]}/{cfg[1:]}/'\n",
    "        t=[os.path.getsize(f'{path}{file}') for file in os.listdir(path)]\n",
    "        assert(np.all(sizes==t))\n",
    "\n",
    "with open('data_aux/cfgs_all_jg','w') as f:\n",
    "    f.write('\\n'.join(cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "83ebb0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# booster\n",
    "# cfgs_all_jsc\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cD211.054.96'\n",
    "\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "path=f'/p/project/ngff/li47/code/projectData/02_discNJN_1D/{ens}/data_pre_jsc/'\n",
    "cfgs=[cfg2new(cfg) for cfg in os.listdir(path) if len(os.listdir(f'{path}{cfg}'))!=0]; cfgs.sort()\n",
    "\n",
    "with open('data_aux/cfgs_all_jsc','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgs_all_jsc=cfgs\n",
    "    \n",
    "with open('data_aux/cfgs_all_jl','r') as f:\n",
    "    cfgs=f.read().splitlines()\n",
    "cfgs_all_jl=cfgs\n",
    "\n",
    "cfgs_all_j=list(set(cfgs_all_jl+cfgs_all_jsc))\n",
    "cfgs_all_j.sort()\n",
    "with open('data_aux/cfgs_all_j','w') as f:\n",
    "    f.write('\\n'.join(cfgs_all_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3763cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfgs_all_N\n",
    "# NsrcDic\n",
    "\n",
    "import os,pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cD211.054.96'\n",
    "\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "path=f'/p/project/ngff/li47/code/projectData/02_discNJN_1D/{ens}/data_pre_N'\n",
    "cfgs=[cfg2new(cfg) for cfg in os.listdir(path)]; cfgs.sort()\n",
    "\n",
    "with open('data_aux/cfgs_all_N','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgs_all_N=cfgs\n",
    "\n",
    "basepath=f'/p/project/ngff/li47/code/projectData/02_discNJN_1D/{ens}/data_post_hold/'\n",
    "\n",
    "# files=['N.h5_nucl_all_source','N.h5_twop_threep_3']\n",
    "# NsrcDic={}\n",
    "# for i,cfg in enumerate(cfgs_all_N):\n",
    "#     print(i+1,len(cfgs_all_N),end='               \\r')\n",
    "#     t=[]\n",
    "#     for file in files:\n",
    "#         path=f'{basepath}{cfg}/{file}'\n",
    "#         if not os.path.exists(path):\n",
    "#             # NsrcDic[(cfg,file)]=0\n",
    "#             t.append(0)\n",
    "#             continue\n",
    "#         with h5py.File(path) as f:\n",
    "#             Nsrc=len(f['data'].keys())\n",
    "#             # NsrcDic[(cfg,file)]=Nsrc\n",
    "#             t.append(Nsrc)\n",
    "#     NsrcDic[cfg]=tuple(t)\n",
    "#     # break\n",
    "\n",
    "# with open('data_aux/NsrcDic.pkl','wb') as f:\n",
    "#     pickle.dump([files,NsrcDic],f)\n",
    "\n",
    "# with open('data_aux/cfgs_all_j','r') as f:\n",
    "#     cfgs=f.read().splitlines()\n",
    "# cfgs_all_j=cfgs\n",
    "\n",
    "# jDic={}\n",
    "# for i,cfg in enumerate(cfgs_all_j):\n",
    "#     print(i+1,len(cfgs_all_j),end='               \\r')\n",
    "#     path=f'{basepath}{cfg}/j.h5'\n",
    "#     with h5py.File(path) as f:\n",
    "#         t=list(f['data'].keys()); t.sort()\n",
    "#         jDic[cfg]=t\n",
    "#     # break\n",
    "\n",
    "# with open('data_aux/jDic.pkl','wb') as f:\n",
    "#     pickle.dump(jDic,f)\n",
    "# cfgs_all_j=cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "313d4fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 499 493\n",
      "494 499 493\n",
      "494 498 493\n"
     ]
    }
   ],
   "source": [
    "import os,pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "skip={'c0164'} # data/j+;g5g{m,Dn};tl contains nan; Conf0164_r2/Ns0/oneD/dir3/loop in S8 contains nan\n",
    "\n",
    "with open('data_aux/NsrcDic.pkl','rb') as f:\n",
    "    files,NsrcDic=pickle.load(f)\n",
    "cfgs_all_N=list(NsrcDic.keys()); cfgs_all_N.sort()\n",
    "cfgs=[]\n",
    "for cfg in cfgs_all_N:\n",
    "    if NsrcDic[cfg] != (256,112):\n",
    "        # print(cfg, NsrcDic[cfg])\n",
    "        continue\n",
    "    # print(cfg, NsrcDic[cfg])\n",
    "    cfgs.append(cfg)\n",
    "with open('data_aux/cfgs_N=256,112','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgsN=cfgs\n",
    "    \n",
    "with open('data_aux/jDic.pkl','rb') as f:\n",
    "    jDic=pickle.load(f)\n",
    "cfgs_all_j=list(jDic.keys()); cfgs_all_j.sort()\n",
    "\n",
    "cfgs=[]\n",
    "for cfg in cfgs_all_j:\n",
    "    if 'j+' not in jDic[cfg]:\n",
    "        # print(cfg,jDic[cfg])\n",
    "        continue\n",
    "    cfgs.append(cfg)\n",
    "with open('data_aux/cfgs_jl','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgsj=cfgs\n",
    "cfgsj=list(set(cfgs)-skip)\n",
    "\n",
    "with open('data_aux/cfgs_all_jg','r') as f:\n",
    "    cfgs=f.read().splitlines()\n",
    "cfgs_jg=cfgs\n",
    "\n",
    "cfgs=list(set(cfgsN).intersection(cfgsj)); cfgs.sort()\n",
    "print(len(cfgsN),len(cfgsj),len(cfgs))\n",
    "with open('data_aux/cfgs_N=256,112_jl','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "    \n",
    "cfgs=[]\n",
    "for cfg in cfgsj:\n",
    "    if len(jDic[cfg]) != 20:\n",
    "        # print(cfg,jDic[cfg])\n",
    "        continue\n",
    "    cfgs.append(cfg)\n",
    "with open('data_aux/cfgs_jlsc','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgsj=cfgs\n",
    "\n",
    "cfgs=list(set(cfgsN).intersection(cfgsj)); cfgs.sort()\n",
    "print(len(cfgsN),len(cfgsj),len(cfgs))\n",
    "with open('data_aux/cfgs_N=256,112_jlsc','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "    \n",
    "cfgsj=set(cfgsj).intersection(cfgs_jg)\n",
    "cfgs=list(set(cfgsN).intersection(cfgsj)); cfgs.sort()\n",
    "print(len(cfgsN),len(cfgsj),len(cfgs))\n",
    "with open('data_aux/cfgs_N=256,112_jlscg','w') as f:\n",
    "    f.write('\\n'.join(cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9b4b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.8324622958943678\n",
      "21 0.8671694802343811\n",
      "22 0.9014240394341506\n",
      "23 0.9352432331448176\n",
      "24 0.9686432512115369\n",
      "25 1.0016393042679264\n",
      "26 1.0342457046990998\n",
      "27 1.0664759391959728\n",
      "28 1.0983427339442244\n",
      "29 1.1298581133416483\n",
      "30 1.1610334530122326\n"
     ]
    }
   ],
   "source": [
    "# Q2 range\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "enss=['b','c','d']\n",
    "ens2full={'a24':'cA211.53.24','a':'cA2.09.48','b':'B64','c':'C80','d':'D96'}\n",
    "ens2label={'a24':'A24','a':'A48','b':'B64','c':'C80','d':'D96'}\n",
    "ens2a={'a24':0.0908,'a':0.0938,'b':0.07957,'c':0.06821,'d':0.05692} # fm\n",
    "ens2N={'a24':24,'a':48,'b':64,'c':80,'d':96}\n",
    "ens2N_T={'a24':24*2,'a':48*2,'b':64*2,'c':80*2,'d':96*2}\n",
    "\n",
    "# ens2mN={'a':931}\n",
    "# ens2mpiC={'a':131}\n",
    "# ens2mpi0={'a':111}\n",
    "\n",
    "ens2amu={'a24':0.0053,'a':0.0009,'b':0.00072}\n",
    "ens2ZP={'a24':(0.4670,0.0046),'a':(0.500,0.030)}\n",
    "\n",
    "hbarc = 1/197.3\n",
    "ens2aInv={ens:1/(ens2a[ens]*hbarc) for ens in enss} # MeV\n",
    "\n",
    "ens='d'\n",
    "\n",
    "for n2 in np.arange(30+1):\n",
    "    mN=0.938\n",
    "    q2=(2*np.pi/(ens2N[ens])*ens2aInv[ens]/1000)**2 * n2\n",
    "    EN=np.sqrt(mN**2+q2)\n",
    "    Q2=q2 - (EN-mN)**2\n",
    "    if Q2>0.8:\n",
    "        print(n2,Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f823d892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cB211.072.64'\n",
    "cfg='a0500'\n",
    "\n",
    "ens='cC211.060.80'\n",
    "cfg='a0500'\n",
    "\n",
    "ens='cD211.054.96'\n",
    "cfg='a0000'\n",
    "\n",
    "\n",
    "path1=f'/p/project/ngff/li47/code/projectData/02_discNJN_1D/{ens}/data_post/{cfg}/j.h5'\n",
    "path2=f'/p/project/ngff/li47/code/temp/{ens}/j.h5_loops-a'\n",
    "\n",
    "with h5py.File(path1) as f1, h5py.File(path2) as f2:\n",
    "    moms1=[list(mom) for mom in f1['moms']]\n",
    "    moms2=[list(mom[-3:]) for mom in f2['moms']]\n",
    "    \n",
    "    momMap1to2=[moms1.index(mom) for mom in moms2]\n",
    "    \n",
    "    ky='data/jc'\n",
    "    t1=f1[ky][:,momMap1to2,:]\n",
    "    t2=f2[ky][:,:,:]\n",
    "    # print(t1)\n",
    "    # print(t2)\n",
    "    print(np.max(np.abs(t1-t2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eae34b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0805156823142814e-14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "path='/p/project/ngff/li47/code/projectData/02_discNJN_1D/cB211.072.64/data_post/a0500/j.h5'\n",
    "path2='/p/project/ngff/li47/code/projectData/NST_f_discBCD/cB211.072.64/data_post/a0500/j.h5'\n",
    "with h5py.File(path) as f1, h5py.File(path2) as f2:\n",
    "    m1=f1['moms'][:]\n",
    "    m2=f2['moms'][:]\n",
    "    # m1=[list(ele) for ele in m1]\n",
    "    # m2=[list(ele) for ele in m2]\n",
    "    # m1.sort()\n",
    "    # m2.sort()\n",
    "    # print(np.all(m1==m2))\n",
    "    \n",
    "    dic1={}\n",
    "    for i,mom in enumerate(m1):\n",
    "        dic1[tuple(mom)]=i\n",
    "    dic2={}\n",
    "    for i,mom in enumerate(m2):\n",
    "        dic2[tuple(mom)]=i\n",
    "    \n",
    "    mom=(0,0,1)\n",
    "    \n",
    "    t1=f1['data/j+_g{m,Dn}_tl'][:,dic1[mom],:]\n",
    "\n",
    "    t2=f2['data/j'][:,dic2[mom],:]\n",
    "    print(np.max(np.abs(t1-t2)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f27f729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 33, 2)\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# path1='/p/project/ngff/li47/code/projectData/02_discNJN_1D/cB211.072.64/data_post/a0500/j_1.h5'\n",
    "# path2='/p/project/ngff/li47/code/projectData/02_discNJN_1D/cB211.072.64/data_post/a0500/j_2.h5'\n",
    "# with h5py.File(path1) as f1,h5py.File(path2) as f2:\n",
    "#     print(f1['data'].keys())\n",
    "#     t1=f1['data/j+_SGM[m{n],Dr}_tl'][:]\n",
    "#     t2=f2['data/j+_SGM[m{n],Dr}_tl'][:]\n",
    "#     print(np.abs(t1-t2))\n",
    "\n",
    "# path1='/p/project/ngff/li47/code/projectData/02_discNJN_1D/cB211.072.64/data_avgsrc/a0500/N-j.h5'\n",
    "# path2='/p/project/ngff/li47/code/projectData/NST_f_discBCD/cB211.072.64/data_avgsrc/a0500/N-j.h5'\n",
    "# with h5py.File(path1) as f1, h5py.File(path2) as f2:\n",
    "#     print(f1['data'].keys())\n",
    "#     print(f2['data'].keys())\n",
    "    \n",
    "#     ky1='N_N_j+_g{m,Dn}_tl_11'\n",
    "#     ky2='N_N_j_11'\n",
    "#     t1=f1[f'data/{ky1}'][:]\n",
    "#     t2=f2[f'data/{ky2}'][:]\n",
    "#     print(np.max(np.abs(t1-t2)))\n",
    "    \n",
    "#     ky1='N_N_j+_g{m,Dn}_tl_11'\n",
    "#     ky2='N_N_j_11'\n",
    "#     t1=f1[f'data_bw/{ky1}'][:]\n",
    "#     t2=f2[f'data_bw/{ky2}'][:]\n",
    "#     print(np.max(np.abs(t1-t2)))\n",
    "\n",
    "# file='N.h5_hch02k_twop'\n",
    "# file='N.h5_twop_threep_2'\n",
    "# file='N.h5_twop_threep_dt20_64srcs'\n",
    "# path1=f'/p/project/ngff/li47/code/projectData/02_discNJN_1D/cB211.072.64/data_post_hold/a0500/{file}'\n",
    "# path2=f'/p/project/ngff/li47/code/projectData/02_discNJN_1D/cB211.072.64/data_N_fullmom/a0500/{file}'\n",
    "# with h5py.File(path1) as f1, h5py.File(path2) as f2:\n",
    "    \n",
    "#     fla='N1_N1'; dat='data'\n",
    "    \n",
    "#     moms1=[list(mom) for mom in f1['moms']]\n",
    "#     moms2=[list(mom) for mom in f2['moms']]\n",
    "#     momMap=[moms2.index(mom) for mom in moms1]\n",
    "#     srcs=list(f1[dat].keys())\n",
    "#     t1=0\n",
    "#     for src in srcs:\n",
    "#         t1+=f1[f'{dat}/{src}/{fla}'][:,:,[0,3]]\n",
    "#     t1/=len(srcs)\n",
    "    \n",
    "#     t2=f2[f'{dat}/{fla}'][:]\n",
    "#     t2=t2[:,momMap]\n",
    "    \n",
    "#     print(t1.shape)\n",
    "#     print(np.max(np.abs((t1-t2)/t1)))\n",
    "#     print(np.max(np.abs(t1-t2)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
