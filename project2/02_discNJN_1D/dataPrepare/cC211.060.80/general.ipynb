{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817f9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyclone\n",
    "# cfgs_all_j\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cC211.060.80'\n",
    "\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "path=f'/nvme/h/cy22yl1/projectData/02_discNJN_1D/{ens}/data_pre_j/'\n",
    "cfgs=[cfg2new(cfg) for cfg in os.listdir(path)]; cfgs.sort()\n",
    "\n",
    "with open('data_aux/cfgs_all_j','w') as f:\n",
    "    f.write('\\n'.join(cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c9fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40         \r"
     ]
    }
   ],
   "source": [
    "# cyclone\n",
    "# cfgs_all_jg\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cC211.060.80'\n",
    "basePath='/onyx/qdata/gspanoudes/Local_operators/Matrix_elements/cC80/data/gluon_loops_stout4D/'\n",
    "stouts=range(40+1)\n",
    "replicas=['cC80a','cC80b']; labels=['a','b']\n",
    "\n",
    "replica2label={replica:label for replica,label in zip(replicas,labels)}\n",
    "label2replica={label:replica for replica,label in zip(replicas,labels)}\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "cfgs=[replica2label[replica]+cfg for replica in replicas for cfg in os.listdir(f'{basePath}stout{0}/{replica}')]\n",
    "cfgs.sort()\n",
    "\n",
    "cfg=cfgs[0]\n",
    "path=f'{basePath}stout{0}/{label2replica[cfg[0]]}/{cfg[1:]}/'\n",
    "sizes=[os.path.getsize(f'{path}{file}') for file in os.listdir(path)]\n",
    "\n",
    "cfgsDic={}\n",
    "for stout in stouts:\n",
    "    print(stout,end='         \\r')\n",
    "    t=[replica2label[replica]+cfg for replica in replicas for cfg in os.listdir(f'{basePath}stout{stout}/{replica}')]\n",
    "    t.sort()\n",
    "    assert(np.all(cfgs==t))\n",
    "    for cfg in cfgs:\n",
    "        path=f'{basePath}stout{stout}/{label2replica[cfg[0]]}/{cfg[1:]}/'\n",
    "        t=[os.path.getsize(f'{path}{file}') for file in os.listdir(path)]\n",
    "        assert(np.all(sizes==t))\n",
    "\n",
    "with open('data_aux/cfgs_all_jg','w') as f:\n",
    "    f.write('\\n'.join(cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3763cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfgs_all_N\n",
    "# NsrcDic\n",
    "\n",
    "import os,pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cC211.060.80'\n",
    "\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "path=f'/p/project/ngff/li47/code/projectData/02_discNJN_1D/{ens}/data_pre_N'\n",
    "cfgs=[cfg2new(cfg) for cfg in os.listdir(path)]; cfgs.sort()\n",
    "\n",
    "with open('data_aux/cfgs_all_N','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgs_all_N=cfgs\n",
    "\n",
    "basepath=f'/p/project/ngff/li47/code/projectData/02_discNJN_1D/{ens}/data_post_hold/'\n",
    "\n",
    "# files=['N.h5_twop_nucl_srcs650']\n",
    "# NsrcDic={}\n",
    "# for i,cfg in enumerate(cfgs_all_N):\n",
    "#     print(i+1,len(cfgs_all_N),end='               \\r')\n",
    "#     t=[]\n",
    "#     for file in files:\n",
    "#         path=f'{basepath}{cfg}/{file}'\n",
    "#         if not os.path.exists(path):\n",
    "#             # NsrcDic[(cfg,file)]=0\n",
    "#             t.append(0)\n",
    "#             continue\n",
    "#         with h5py.File(path) as f:\n",
    "#             Nsrc=len(f['data'].keys())\n",
    "#             # NsrcDic[(cfg,file)]=Nsrc\n",
    "#             t.append(Nsrc)\n",
    "#     NsrcDic[cfg]=tuple(t)\n",
    "#     # break\n",
    "\n",
    "# with open('data_aux/NsrcDic.pkl','wb') as f:\n",
    "#     pickle.dump([files,NsrcDic],f)\n",
    "\n",
    "# with open('data_aux/cfgs_all_j','r') as f:\n",
    "#     cfgs=f.read().splitlines()\n",
    "# cfgs_all_j=cfgs\n",
    "\n",
    "# jDic={}\n",
    "# for i,cfg in enumerate(cfgs_all_j):\n",
    "#     print(i+1,len(cfgs_all_j),end='               \\r')\n",
    "#     path=f'{basepath}{cfg}/j.h5'\n",
    "#     with h5py.File(path) as f:\n",
    "#         t=list(f['data'].keys()); t.sort()\n",
    "#         jDic[cfg]=t\n",
    "#     # break\n",
    "\n",
    "# with open('data_aux/jDic.pkl','wb') as f:\n",
    "#     pickle.dump(jDic,f)\n",
    "# cfgs_all_j=cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313d4fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 401 401\n",
      "401 400 400\n",
      "401 400 400\n"
     ]
    }
   ],
   "source": [
    "import os,pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with open('data_aux/NsrcDic.pkl','rb') as f:\n",
    "    files,NsrcDic=pickle.load(f)\n",
    "cfgs_all_N=list(NsrcDic.keys()); cfgs_all_N.sort()\n",
    "cfgs=[]\n",
    "for cfg in cfgs_all_N:\n",
    "    if NsrcDic[cfg] != (650,):\n",
    "        # print(cfg, NsrcDic[cfg])\n",
    "        continue\n",
    "    # print(cfg, NsrcDic[cfg])\n",
    "    cfgs.append(cfg)\n",
    "with open('data_aux/cfgs_N=650','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgsN=cfgs\n",
    "    \n",
    "with open('data_aux/jDic.pkl','rb') as f:\n",
    "    jDic=pickle.load(f)\n",
    "cfgs_all_j=list(jDic.keys()); cfgs_all_j.sort()\n",
    "\n",
    "cfgs=[]\n",
    "for cfg in cfgs_all_j:\n",
    "    if 'j+' not in jDic[cfg]:\n",
    "        # print(cfg,jDic[cfg])\n",
    "        continue\n",
    "    cfgs.append(cfg)\n",
    "with open('data_aux/cfgs_jl','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgsj=cfgs\n",
    "\n",
    "with open('data_aux/cfgs_all_jg','r') as f:\n",
    "    cfgs=f.read().splitlines()\n",
    "cfgs_jg=cfgs\n",
    "\n",
    "cfgs=list(set(cfgsN).intersection(cfgsj)); cfgs.sort()\n",
    "print(len(cfgsN),len(cfgsj),len(cfgs))\n",
    "with open('data_aux/cfgs_N=650_jl','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "\n",
    "cfgs=[]\n",
    "for cfg in cfgs_all_j:\n",
    "    if len(jDic[cfg]) != 20:\n",
    "        # print(cfg,jDic[cfg])\n",
    "        continue\n",
    "    cfgs.append(cfg)\n",
    "with open('data_aux/cfgs_jlsc','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "cfgsj=cfgs\n",
    "\n",
    "cfgs=list(set(cfgsN).intersection(cfgsj)); cfgs.sort()\n",
    "print(len(cfgsN),len(cfgsj),len(cfgs))\n",
    "with open('data_aux/cfgs_N=650_jlsc','w') as f:\n",
    "    f.write('\\n'.join(cfgs))\n",
    "    \n",
    "cfgsj=set(cfgsj).intersection(cfgs_jg)\n",
    "cfgs=list(set(cfgsN).intersection(cfgsj)); cfgs.sort()\n",
    "print(len(cfgsN),len(cfgsj),len(cfgs))\n",
    "with open('data_aux/cfgs_N=650_jlscg','w') as f:\n",
    "    f.write('\\n'.join(cfgs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
